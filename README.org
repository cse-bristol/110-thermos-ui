#+TITLE: Thermos UI

n.b. July 2025
On buzz Thermos is using Postgres 13.7 which is the default from nixos 21.11, so it's this channel that's set in envrc.buzz /.envrc


See LICENSE for licensing information.

THERMOS as a whole is split into a few parts, which see:

- https://github.com/cse-bristol/clj-lp :: a library for driving MIP solvers from clojure
- https://github.com/cse-bristol/110-thermos-models :: a library containing most of the core THERMOS MIP / heuristic models
- https://github.com/cse-bristol/110-thermos-importer :: a library containing utility code, mostly for processing GIS data
- https://github.com/cse-bristol/110-thermos-ui :: this repository, containing the THERMOS frontend application.

  A certain amount of model code is also in this repository, since the thermos-models interfaces accept a boiled down version in which some simplifications have been made already. In particular, the rules for heat losses, pipe diameters, and pipe costs are all found in here.

* This repository

The THERMOS web interface.

Builds using scripts in build-src.

* How to build

- For development
  
  1. You need a postgis server to run against.
     There is a nix expression to set one up in [[./dev/pg-server.nix]]
  2. You need a JDK
  3. You need clojure command line tools

  Then you can run

  #+BEGIN_EXAMPLE sh
  clojure -Adev:server:client dev
  #+END_EXAMPLE

  or
  
  #+BEGIN_EXAMPLE sh
  clojure -Adev:server:client dev --emacs
  #+END_EXAMPLE

  if you want to develop in emacs with cider.

  If you want to hack on the dependencies locally as well, you can check them out into ../, and do

  #+BEGIN_EXAMPLE sh
  clojure -Adev:server:client:local-deps dev
  #+END_EXAMPLE

- For production
  
  #+BEGIN_EXAMPLE sh
  clojure -Adev:server:client pkg
  #+END_EXAMPLE

  Should spit out a jar in target/

* Production deployment on buzz

- Deploy after building

  #+BEGIN_EXAMPLE sh
  cd /srv/nixops/110-thermos-tool/live
  sudo nixops deploy -d thermos-live
  #+END_EXAMPLE

- Access container shell

  #+BEGIN_EXAMPLE sh
  nixops ssh -d thermos-live thermos-app
  #+END_EXAMPLE

- Other nixops command lines that might be useful

  #+BEGIN_EXAMPLE sh
  nixops info -d thermos-live
  nixops ssh-for-each -d thermos-live
  nixops deploy --debug -d thermos-live
  #+END_EXAMPLE

* Configuration

The application has a few config settings, defaults in ~resources/config.edn~.
These are settable through the environment.

* How to move things between databases

e.g. for a given user

#+begin_src sql
  CREATE TABLE export_projects AS
  SELECT * FROM projects WHERE id IN
  (SELECT project_id FROM users_projects WHERE user_id = 'user@domain.com');

  CREATE TABLE export_maps AS
  SELECT * FROM maps WHERE project_id IN
  (SELECT id FROM export_projects);

  CREATE TABLE export_candidates AS
  SELECT * FROM candidates WHERE map_id IN
  (SELECT id FROM export_maps);

  CREATE TABLE export_buildings AS
  SELECT * FROM buildings WHERE candidate_id IN
  (SELECT id FROM export_candidates);

  CREATE TABLE export_buildings AS
  SELECT * FROM buildings WHERE candidate_id IN
  (SELECT id FROM export_candidates);

  CREATE TABLE export_paths AS
  SELECT * FROM paths WHERE candidate_id IN
  (SELECT id FROM export_candidates);

  CREATE TABLE export_networks AS
  SELECT * FROM networks WHERE map_id IN
  (SELECT id FROM export_maps);

  CREATE TABLE export_map_centres AS
  SELECT * FROM map_centres where map_id in
  (select id from export_maps);

  CREATE TABLE export_map_icons AS
  SELECT * FROM map_icons where map_id in
  (select id from export_maps);
#+end_src

dump the created tables

#+begin_src sh
  pg_dump -U postgres thermos \
          -t export_projects \
          -t export_maps \
          -t export_networks \
          -t export_candidates \
          -t export_buildings \
          -t export_paths \
          -t export_map_icons \
          -t export_map_centres | gzip > export.sql.gz
#+end_src

load them at the other side

#+begin_src sh
  zcat export.sql.gz | psql -U postgres thermos

  or

  zcat export.sql.gz | nixops ssh -d thermos-live thermos-app psql -U postgres 
-d thermos # on buzz
#+end_src

insert them into the database and remap their IDs

#+begin_src sql
  BEGIN;

  ALTER TABLE projects ADD COLUMN import_id INTEGER;
  ALTER TABLE maps ADD COLUMN import_id INTEGER;
  ALTER TABLE networks ADD COLUMN import_id INTEGER;
  ALTER TABLE candidates ADD COLUMN import_id INTEGER;

  CREATE INDEX ON projects(import_id);
  CREATE INDEX ON maps(import_id);
  CREATE INDEX ON networks(import_id);
  CREATE INDEX ON candidates(import_id);

  CREATE INDEX ON export_projects(id);
  CREATE INDEX ON export_maps(id);
  CREATE INDEX ON export_networks(id);
  CREATE INDEX ON export_candidates(id);
  CREATE INDEX ON export_buildings(candidate_id);
  CREATE INDEX ON export_paths(candidate_id);


  INSERT INTO projects (name, description, public, import_id)
  (SELECT name, description, public, id FROM export_projects);

  INSERT INTO maps (project_id, name, parameters, import_completed, estimation_stats, import_id)
  (SELECT (SELECT id FROM projects WHERE import_id = project_id), name, parameters, import_completed, estimation_stats, id from export_maps);

  INSERT INTO networks (map_id, name, content, created, has_run, user_id, version, meta)
  (SELECT (SELECT id FROM maps WHERE import_id = map_id), name, content, created, has_run, user_id, version, meta from export_networks);

  INSERT INTO candidates (geoid, orig_id, geometry, map_id, user_fields, import_id)
  (SELECT geoid, orig_id, geometry, (SELECT id FROM maps WHERE import_id = map_id), user_fields, id from export_candidates);

  INSERT INTO buildings (connection_id, demand_kwh_per_year, demand_kwp, connection_count, candidate_id, peak_source, demand_source, floor_area, height, wall_area, roof_area, ground_area, cooling_kwh_per_year, cooling_kwp, conn_group)
  (SELECT connection_id, demand_kwh_per_year, demand_kwp, connection_count, candidates.id, peak_source, demand_source, floor_area, height, wall_area, roof_area, ground_area, cooling_kwh_per_year, cooling_kwp, conn_group FROM export_buildings JOIN candidates ON export_buildings.candidate_id = candidates.import_id AND candidates.import_id IS NOT NULL);

  INSERT INTO paths (start_id, end_id, length, candidate_id)
  (SELECT start_id, end_id, length, candidates.id FROM export_paths JOIN candidates ON export_paths.candidate_id = candidates.import_id AND candidates.import_id IS NOT NULL);

  INSERT INTO map_centres (map_id, envelope)
  (SELECT (SELECT id FROM maps WHERE import_id = map_id), envelope FROM export_map_centres);

  INSERT INTO map_icons (png, map_id)
  (SELECT png, (SELECT id FROM maps WHERE import_id = map_id) FROM export_map_icons);

  INSERT INTO users_projects (project_id, user_id, auth)
  (SELECT id FROM projects WHERE import_id IS NOT NULL, 'xxx', 'admin');

  ALTER TABLE projects DROP COLUMN import_id ;
  ALTER TABLE maps DROP COLUMN import_id ;
  ALTER TABLE networks DROP COLUMN import_id ;
  ALTER TABLE candidates DROP COLUMN import_id ;

  DROP TABLE export_projects ;
  DROP TABLE export_maps ;
  DROP TABLE export_networks ;
  DROP TABLE export_candidates ;
  DROP TABLE export_buildings ;
  DROP TABLE export_paths ;
  DROP TABLE export_map_icons ;
  DROP TABLE export_map_centre;

  COMMIT;
#+end_src

The insert from select can be very slow; may want to disable indexes, insert and rebuild

e.g.

#+begin_src sql
   update pg_index set indisready=[true, false] where indrelid = (select oid from pg_class where
  relname = 'buildings');
  reindex buildings;
#+end_src
